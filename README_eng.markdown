# QSAR Analysis of Compounds Against Influenza Virus

This project performs Quantitative Structure-Activity Relationship (QSAR) analysis on 1000 chemical compounds to predict their antiviral activity, cytotoxicity, and selectivity against the influenza virus. It includes machine learning regression and classification models, data visualizations, and automated report generation in Markdown and PDF formats.

## Project Overview

The project addresses the following tasks:
- **Data Preprocessing**: Analysis and cleaning of data from `data/coursework_data.xlsx`, generating `data/processed_data.csv`.
- **Regression**: Prediction of log-transformed values:
  - `log_ic50` (antiviral activity, IC50_mM).
  - `log_cc50` (cytotoxicity, CC50_mM).
  - `log_si` (selectivity index, SI).
- **Classification**: Binary classification:
  - `IC50_mM`, `CC50_mM`, `SI` based on median values.
  - `SI > 8` (in logarithmic scale: `log_si >= log10(8)`).
- **Models**: Utilizes `RandomForest`, `XGBoost`, `LightGBM`, `GradientBoosting`, `LinearRegression`/`LogisticRegression`, and ensembles (`VotingRegressor`/`VotingClassifier`).
- **Optimization**: Model hyperparameters are optimized using [Optuna](https://optuna.org/).
- **Visualizations**: Histograms, boxplots, correlation matrices (EDA); feature importance plots, predicted vs. true value plots (regression); confusion matrices, ROC curves (classification, except for `SI > 8`).
- **Reporting**: Generates a report in `results/report.md` and converts it to PDF (`results/report_[timestamp].pdf`).

## Requirements

- **Python**: Version 3.12.
- **Python Libraries**: Listed in `requirements.txt`.
- **System Dependencies** (for `weasyprint` on Ubuntu):
  ```bash
  sudo apt-get install libcairo2 libpango-1.0-0
  ```
- **Input File**: `data/coursework_data.xlsx` (must be in the `data/` directory).

**Note**: Some libraries (e.g., `weasyprint`) require system packages. In server environments, ensure `matplotlib` uses the `Agg` backend. The deprecated `pkg_resources` module may trigger warnings; consider migrating to `importlib.metadata` in future updates.

## Installation

1. Clone the repository:
   ```bash
   git clone <repository_URL>
   cd qsar_an1
   ```
2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   venv\Scripts\activate     # Windows
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Install system libraries (for Ubuntu):
   ```bash
   sudo apt-get install libcairo2 libpango-1.0-0
   ```
5. Ensure `data/coursework_data.xlsx` is in the `data/` directory.

## Project Structure

- **data/**: Stores input and processed data.
  - `coursework_data.xlsx`: Raw input data.
  - `processed_data.csv`: Processed data (generated by `eda.py`).
- **scripts/**: Python scripts.
  - `eda.py`: Data preprocessing and exploratory analysis.
  - `regression_log_ic50.py`, `regression_log_cc50.py`, `regression_log_si.py`: Regression tasks.
  - `classification_cc50_median.py`, `classification_ic50_median.py`, `classification_si_median.py`, `classification_si_8.py`: Classification tasks.
  - `generate_report.py`: Generates the Markdown report.
  - `convert_to_pdf.py`: Converts the report to PDF.
- **results/**: Model results and reports.
  - `regression_*.csv`, `classification_*.csv`: Model metrics.
  - `report.md`, `report_[timestamp].pdf`: Generated reports.
- **figures/**: Visualizations.
  - `histograms.png`, `boxplots.png`, `correlation.png`: EDA outputs.
  - `feature_importance_*.png`, `pred_vs_true_*.png`: Regression visualizations.
  - `confusion_matrix_*.png`, `roc_curve_*.png`, `feature_importance_*.png`: Classification visualizations.
- **logs/**: Log files for each script (`eda.log`, `regression_*.log`, `classification_*.log`, etc.).
- **main.py**: Orchestrates the execution of all scripts.
- **requirements.txt**: Lists dependencies.
- **README_rus.md**, **README_eng.md**: Documentation.

## Usage

1. Ensure `data/coursework_data.xlsx` is in the `data/` directory.
2. Run the main script:
   ```bash
   python main.py
   ```
   - To continue execution despite errors, use:
     ```bash
     python main.py --continue-on-error
     ```
3. Execution sequence:
   - `eda.py`: Processes data, generates `processed_data.csv`, and creates visualizations (`figures/histograms.png`, `boxplots.png`, `correlation.png`).
   - Regression: Trains models for `log_ic50`, `log_cc50`, `log_si`, saves metrics (`results/regression_*.csv`) and visualizations (`figures/feature_importance_*.png`, `pred_vs_true_*.png`).
   - Classification: Trains models for `IC50_mM`, `CC50_mM`, `SI` (median-based) and `SI > 8`, saves metrics (`results/classification_*.csv`) and visualizations (`figures/confusion_matrix_*.png`, `roc_curve_*.png`, `feature_importance_*.png`).
   - `generate_report.py`: Creates `results/report.md`.
   - `convert_to_pdf.py`: Converts the report to `results/report_[timestamp].pdf`.

## Outputs

- **CSV Files** (`results/`):
  - Regression: `regression_log_ic50.csv`, `regression_log_cc50.csv`, `regression_log_si.csv` (metrics: `MSE`, `R2`, `MAE`).
  - Classification: `classification_cc50_median.csv`, `classification_ic50_median.csv`, `classification_si_median.csv`, `classification_si_8.csv` (metrics: `Accuracy`, `F1`, `Precision`, `Recall`, `ROC_AUC`, `PR_AUC`, except for `SI > 8`).
- **Visualizations** (`figures/`):
  - EDA: Histograms, boxplots, correlation matrix.
  - Regression: Feature importance plots, predicted vs. true value plots.
  - Classification: Confusion matrices, ROC curves (except for `SI > 8`), feature importance plots.
- **Report**:
  - `results/report.md`: Text-based report with embedded visualizations.
  - `results/report_[timestamp].pdf`: PDF version of the report.
- **Logs** (`logs/`): Detailed execution logs for each script.

## Notes

- The script will fail if `data/coursework_data.xlsx` is missing.
- In server environments, configure `matplotlib` to use the `Agg` backend (e.g., add `matplotlib.use('Agg')` to `regression_log_cc50.py`).
- The `classification_si_8.py` script uses `accuracy` instead of `F1` and does not generate ROC curves, limiting comparability with other classification tasks.
- To speed up training, set `n_jobs=-1` instead of `n_jobs=1` in scripts (e.g., `regression_log_ic50.py`), but this may reduce `Optuna` stability.
- The `reports/` directory may be deprecated; reports are saved in `results/`.
- For further optimization, consider increasing `Optuna` iterations or enabling cross-validation in scripts.

## References
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Weasyprint Documentation](https://weasyprint.readthedocs.io/)
- [scikit-learn Documentation](https://scikit-learn.org/stable/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)